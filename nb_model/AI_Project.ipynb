{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Emki787old",
        "outputId": "edce3b10-9e11-4178-d313-9737a050b265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.87\n",
            "Precision: 1.00\n",
            "Recall: 0.73\n",
            "F1 Score: 0.85\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8666666666666667, 1.0, 0.7333333333333333, 0.846153846153846)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import json\n",
        "import zipfile\n",
        "import joblib\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.spam_prob = 0\n",
        "        self.ham_prob = 0\n",
        "        self.spam_word_probs = defaultdict(float)\n",
        "        self.ham_word_probs = defaultdict(float)\n",
        "        self.vocab = set()\n",
        "\n",
        "    def save_model(self, file_path='nb_model.joblib'):\n",
        "        joblib.dump(self, file_path)\n",
        "\n",
        "    def load_model(self, file_path='nb_model.joblib'):\n",
        "        loaded_classifier = joblib.load(file_path)\n",
        "        self.__dict__.update(loaded_classifier.__dict__)\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        # Simple text preprocessing: lowercase and remove non-alphabetic characters\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-zA-Z ]', '', text)\n",
        "        return text\n",
        "\n",
        "    def train(self, training_data):\n",
        "        spam_count = ham_count = 0\n",
        "        spam_word_counts = defaultdict(int)\n",
        "        ham_word_counts = defaultdict(int)\n",
        "\n",
        "        for text, label in training_data:\n",
        "            text = self.preprocess_text(text)\n",
        "            words = text.split()\n",
        "            for word in words:\n",
        "                if label == 'spam':\n",
        "                    spam_word_counts[word] += 1\n",
        "                else:\n",
        "                    ham_word_counts[word] += 1\n",
        "                self.vocab.add(word)\n",
        "\n",
        "            if label == 'spam':\n",
        "                spam_count += 1\n",
        "            else:\n",
        "                ham_count += 1\n",
        "\n",
        "        total_emails = spam_count + ham_count\n",
        "        self.spam_prob = spam_count / total_emails\n",
        "        self.ham_prob = ham_count / total_emails\n",
        "\n",
        "        for word in self.vocab:\n",
        "            # Laplace smoothing to handle unseen words\n",
        "            self.spam_word_probs[word] = (spam_word_counts[word] + 1) / (spam_count + 2)\n",
        "            self.ham_word_probs[word] = (ham_word_counts[word] + 1) / (ham_count + 2)\n",
        "\n",
        "    def predict(self, text):\n",
        "        text = self.preprocess_text(text)\n",
        "        words = text.split()\n",
        "\n",
        "        spam_score = math.log(self.spam_prob)\n",
        "        ham_score = math.log(self.ham_prob)\n",
        "\n",
        "        for word in words:\n",
        "            if word in self.vocab:\n",
        "                spam_score += math.log(self.spam_word_probs[word])\n",
        "                ham_score += math.log(self.ham_word_probs[word])\n",
        "\n",
        "        confidence = abs(spam_score - ham_score)\n",
        "\n",
        "        # Classify as spam if the spam_score is greater\n",
        "        predicted_class = 'spam' if spam_score > ham_score else 'ham'\n",
        "\n",
        "        return {'prediction': predicted_class, 'confidence': confidence}\n",
        "\n",
        "\n",
        "    def train_from_directory(self, zip_file_path):\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('./')\n",
        "\n",
        "        directory = './emails'\n",
        "\n",
        "        ham_folder = os.path.join(directory, 'ham')\n",
        "        spam_folder = os.path.join(directory, 'spam')\n",
        "\n",
        "        ham_emails = [(self.read_email(os.path.join(ham_folder, f)), 'ham') for f in os.listdir(ham_folder)]\n",
        "        spam_emails = [(self.read_email(os.path.join(spam_folder, f)), 'spam') for f in os.listdir(spam_folder)]\n",
        "\n",
        "        # Split emails into training, validation, and test sets\n",
        "        random.shuffle(ham_emails)\n",
        "        random.shuffle(spam_emails)\n",
        "\n",
        "        ham_train_size = int(0.7 * len(ham_emails))\n",
        "        spam_train_size = int(0.7 * len(spam_emails))\n",
        "\n",
        "        training_data = ham_emails[:ham_train_size] + spam_emails[:spam_train_size]\n",
        "        validation_data = ham_emails[ham_train_size:] + spam_emails[spam_train_size:]\n",
        "\n",
        "        # Update the vocab based on the new data\n",
        "        self.train(training_data)\n",
        "\n",
        "        # Save the model to a JSON file\n",
        "        model_data = {\n",
        "            'spam_prob': self.spam_prob,\n",
        "            'ham_prob': self.ham_prob,\n",
        "            'spam_word_probs': dict(self.spam_word_probs),\n",
        "            'ham_word_probs': dict(self.ham_word_probs),\n",
        "            'vocab': list(self.vocab)\n",
        "        }\n",
        "\n",
        "        with open('nb_model.json', 'w') as json_file:\n",
        "            json.dump(model_data, json_file)\n",
        "\n",
        "        return validation_data\n",
        "\n",
        "    def evaluate_model(self, validation_data):\n",
        "        test_texts, true_labels = zip(*validation_data)\n",
        "        results = [self.predict(text) for text in test_texts]\n",
        "        predicted_labels = [result['prediction'] for result in results]\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        precision = precision_score(true_labels, predicted_labels, pos_label='spam')\n",
        "        recall = recall_score(true_labels, predicted_labels, pos_label='spam')\n",
        "        f1 = f1_score(true_labels, predicted_labels, pos_label='spam')\n",
        "\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "        return accuracy, precision, recall, f1\n",
        "\n",
        "    def read_email(self, file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            return file.read()\n",
        "\n",
        "\n",
        "# # Small example:\n",
        "# training_data = [(\"Buy now, limited offer!\", \"spam\"), (\"Meeting at 2 pm tomorrow\", \"ham\")]\n",
        "# test_email = \"Special offer just for you!\"\n",
        "# classifier = NaiveBayesClassifier()\n",
        "# classifier.train(training_data)\n",
        "# prediction = classifier.predict(test_email)\n",
        "# print(f\"The email is classified as: {prediction}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier()\n",
        "validation_data = classifier.train_from_directory('emails.zip')\n",
        "classifier.save_model()\n",
        "classifier.evaluate_model(validation_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFI4zgWNcZ-Y",
        "outputId": "f9be589a-8319-4366-d36d-3d6aed825851"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.87\n",
            "Precision: 1.00\n",
            "Recall: 0.73\n",
            "F1 Score: 0.85\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8666666666666667, 1.0, 0.7333333333333333, 0.846153846153846)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email_1 = \"\"\"\n",
        "Thank you for your purchase. We appreciate your business and want to ensure your satisfaction.\n",
        "\n",
        "    To show our appreciation, we're offering you an exclusive discount on your next purchase. Simply use the promo code THANKYOU15 at checkout to enjoy a 15% discount on your entire order.\n",
        "\n",
        "    This special offer is valid for the next 7 days, so don't miss out. Shop now and save on your favorite products!\n",
        "\n",
        "    [Shop Now]\n",
        "\n",
        "    We look forward to serving you again soon.\n",
        "\n",
        "    Best regards,\n",
        "    Customer Support Team\n",
        "\"\"\"\n",
        "\n",
        "email_2 = \"\"\"\n",
        "Limited-time Offer: Save 50% Today!\n",
        "\n",
        "      Congratulations! You've been selected for an exclusive limited-time offer. Shop now and enjoy a 50% discount on a wide range of products.\n",
        "\n",
        "      Use code SAVE50 at checkout to claim your discount. This offer is very real and valid until 31st December. Don't miss out on the savings.\n",
        "\n",
        "      Visit our online store and start shopping today!\n",
        "\n",
        "      [Shop Now]\n",
        "\n",
        "      Yours sincerely,\n",
        "      Nigerian prince\n",
        "\"\"\"\n",
        "\n",
        "prediction_1 = classifier.predict(email_1)\n",
        "prediction_2 = classifier.predict(email_2)\n",
        "\n",
        "print(f\"Prediction for Email 1: {prediction_1}\")\n",
        "print(f\"Prediction for Email 2: {prediction_2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h9rWLtjfC4w",
        "outputId": "be46f235-7959-4cd9-90ac-20c6637942cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for Email 1: {'prediction': 'ham', 'confidence': 27.134136473557845}\n",
            "Prediction for Email 2: {'prediction': 'ham', 'confidence': 15.034556555109589}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('emails_split.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('./')\n",
        "\n",
        "def words(filename):\n",
        "\t# Get list of lines\n",
        "\tinfile = open(filename,'r')\n",
        "\tlines = infile.readlines()\n",
        "\tinfile.close()\n",
        "\n",
        "\t# For each line, delimit word by space\n",
        "\t# and add to list of words. Also, convert\n",
        "\t# all words to lowercase for convenience\n",
        "\treturn [word.strip().lower() for line in lines for word in line.split()]\n",
        "\n",
        "def lexicon(k):\n",
        "\t# Extract training directories\n",
        "\tspam_training_directory = os.getcwd() + '/emails_split/spam'\n",
        "\tham_training_directory  = os.getcwd() + '/emails_split/ham'\n",
        "\n",
        "\t# Create spam distribution\n",
        "\tspam_distribution = {}\n",
        "\tfiles = os.listdir(spam_training_directory)\n",
        "\tfor file in files:\n",
        "\t\tlist_of_words = words(spam_training_directory + '/' + file)\n",
        "\t\tfor word in list_of_words:\n",
        "\t\t\tif word in spam_distribution:\n",
        "\t\t\t\tspam_distribution[word] += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tspam_distribution[word] = 1\n",
        "\n",
        "\t# Create ham distribution\n",
        "\tham_distribution = {}\n",
        "\tfiles = os.listdir(ham_training_directory)\n",
        "\tfor file in files:\n",
        "\t\tlist_of_words = words(ham_training_directory + '/' + file)\n",
        "\t\tfor word in list_of_words:\n",
        "\t\t\tif word in ham_distribution:\n",
        "\t\t\t\tham_distribution[word] += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tham_distribution[word] = 1\n",
        "\n",
        "\t# Remove all key,value pairs that\n",
        "\t# have a value less than k\n",
        "\thamkeys  = list(ham_distribution.keys())\n",
        "\tspamkeys = list(spam_distribution.keys())\n",
        "\n",
        "\tfor key in spamkeys:\n",
        "\t\tif spam_distribution[key] < k:\n",
        "\t\t\tdel spam_distribution[key]\n",
        "\n",
        "\tfor key in hamkeys:\n",
        "\t\tif ham_distribution[key] < k:\n",
        "\t\t\tdel ham_distribution[key]\n",
        "\n",
        "\treturn ham_distribution, spam_distribution\n",
        "\n",
        "def probability(word, category, ham_distribution, spam_distribution, m):\n",
        "\t# Compute P(w = word | category), smoothing the result\n",
        "\t# with Laplacian Smoothing with parameter m\n",
        "\n",
        "\tdistribution = ham_distribution if category == 'ham' else spam_distribution\n",
        "\n",
        "\tV = len(distribution)\n",
        "\n",
        "\tkeys = distribution.keys()\n",
        "\n",
        "\tnumerator = (distribution[word] + m if word in keys else m)\n",
        "\tdenominator = sum([distribution[key] for key in keys]) + m*V\n",
        "\n",
        "\treturn numerator / float(denominator)\n",
        "\n",
        "def classify_email(email, ham_distribution, spam_distribution, m):\n",
        "\temail_words = words(email)\n",
        "\n",
        "\tham_probability  = 0\n",
        "\tspam_probability = 0\n",
        "\n",
        "\tfor word in email_words:\n",
        "\t\tham_probability  += math.log(probability(word, 'ham', ham_distribution, spam_distribution, m))\n",
        "\t\tspam_probability += math.log(probability(word, 'spam', ham_distribution, spam_distribution, m))\n",
        "\n",
        "\treturn 'ham' if ham_probability > spam_probability else 'spam'\n",
        "\n",
        "def test_filter(hamtesting, spamtesting, k, m):\n",
        "\tham_distribution, spam_distribution = lexicon(k)\n",
        "\n",
        "\tspam_as_ham = []\n",
        "\tham_as_spam = []\n",
        "\n",
        "\tham_hit   = 0\n",
        "\tham_total = 0\n",
        "\tham_testing_files = os.listdir(hamtesting)\n",
        "\tfor file in ham_testing_files:\n",
        "\t\tif classify_email(hamtesting + '/' + file, ham_distribution, spam_distribution, m) == 'ham':\n",
        "\t\t\tham_hit += 1\n",
        "\t\telse:\n",
        "\t\t\tham_as_spam.append(file)\n",
        "\t\tham_total += 1\n",
        "\n",
        "\tspam_hit   = 0\n",
        "\tspam_total = 0\n",
        "\tspam_testing_files = os.listdir(spamtesting)\n",
        "\tfor file in spam_testing_files:\n",
        "\t\tif classify_email(spamtesting + '/' + file, ham_distribution, spam_distribution, m) == 'spam':\n",
        "\t\t\tspam_hit += 1\n",
        "\t\telse:\n",
        "\t\t\tspam_as_ham.append(file)\n",
        "\t\tspam_total += 1\n",
        "\n",
        "\tham_hit_ratio  = ham_hit / float(ham_total)\n",
        "\tspam_hit_ratio = spam_hit / float(spam_total)\n",
        "\n",
        "\treturn ham_hit_ratio, spam_hit_ratio, ham_total, spam_total, ham_as_spam, spam_as_ham\n",
        "\n",
        "# ---------- CODE STARTS HERE ----------\n",
        "\n",
        "spamtesting = os.getcwd() + '/emails_split/spam_test'\n",
        "hamtesting  = os.getcwd() + '/emails_split/ham_test'\n",
        "\n",
        "ham_hit_ratio, spam_hit_ratio, ham_total, spam_total, ham_as_spam, spam_as_ham = test_filter(hamtesting, spamtesting, k=5, m=1)\n",
        "\n",
        "print ()\n",
        "print (\"Correct Ham Percentage:     \", ham_hit_ratio * 100)\n",
        "print (\"Correct Spam Percentage:    \", spam_hit_ratio * 100)\n",
        "print (\"Correct Overall Percentage: \", (ham_hit_ratio*ham_total + spam_hit_ratio*spam_total) / (ham_total + spam_total) * 100)\n",
        "\n",
        "print (\"\\nHam Incorrectly Labelled as Spam:\")\n",
        "for file in ham_as_spam:\n",
        "\tprint (\"\\t\"+file)\n",
        "\n",
        "print (\"\\nSpam Incorrectly Labelled as Ham:\")\n",
        "for file in spam_as_ham:\n",
        "\tprint (\"\\t\"+file)\n",
        "print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8nsUNKnsT8M",
        "outputId": "0bd0b143-f17c-4868-b16d-d7f74c0e38ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correct Ham Percentage:      100.0\n",
            "Correct Spam Percentage:     80.95238095238095\n",
            "Correct Overall Percentage:  90.47619047619048\n",
            "\n",
            "Ham Incorrectly Labelled as Spam:\n",
            "\n",
            "Spam Incorrectly Labelled as Ham:\n",
            "\tspam2.txt\n",
            "\tspam1.txt\n",
            "\tspam13.txt\n",
            "\tspamSample.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function print>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}